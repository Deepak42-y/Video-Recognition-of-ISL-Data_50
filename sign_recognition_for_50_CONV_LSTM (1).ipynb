{"cells":[{"cell_type":"code","execution_count":null,"id":"1790a3c7","metadata":{"id":"1790a3c7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706252332086,"user_tz":-330,"elapsed":12305,"user":{"displayName":"DEEPAK YADAV","userId":"03063919201015741773"}},"outputId":"091809e4-0008-46f1-efba-ffb35dbdaf53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Collecting youtube-dl\n","  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.4)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Installing collected packages: youtube-dl\n","Successfully installed youtube-dl-2021.12.17\n"]}],"source":["# Discard the output of this cell.\n","#%%capture\n","\n","# Install the required libraries.\n","!pip install tensorflow opencv-contrib-python youtube-dl moviepy pydot\n","# !pip install git+https://github.com/TahaAnwar/pafy.git#egg=pafy"]},{"cell_type":"code","execution_count":null,"id":"AJjQZIAJFDEu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28855,"status":"ok","timestamp":1706252218505,"user":{"displayName":"DEEPAK YADAV","userId":"03063919201015741773"},"user_tz":-330},"id":"AJjQZIAJFDEu","outputId":"384c12d3-b0a5-49aa-a768-1f6a27481906"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"32e10dac","metadata":{"id":"32e10dac"},"outputs":[],"source":["# Import the required libraries.\n","# !pip install tensorflow\n","import os\n","import cv2\n","# import pafy\n","import math\n","import random\n","import numpy as np\n","import datetime as dt\n","import tensorflow as tf\n","from collections import deque\n","import matplotlib.pyplot as plt\n","\n","from moviepy.editor import *\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n"]},{"cell_type":"code","execution_count":null,"id":"ff7c30c5","metadata":{"id":"ff7c30c5"},"outputs":[],"source":["seed_constant = 27\n","np.random.seed(seed_constant)\n","random.seed(seed_constant)\n","tf.random.set_seed(seed_constant)"]},{"cell_type":"code","execution_count":null,"id":"1ba6f330","metadata":{"id":"1ba6f330","outputId":"7e6ff84a-1840-413d-a45f-89ac1a608bd7","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1UE5mCNbRnfKA-jbdISXE-7sRCX2BrBhp"},"executionInfo":{"status":"ok","timestamp":1706252392704,"user_tz":-330,"elapsed":25734,"user":{"displayName":"DEEPAK YADAV","userId":"03063919201015741773"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["\n","plt.figure(figsize=(20, 20))\n","\n","all_classes_names = os.listdir(\"/content/drive/MyDrive/isl_data50\")\n","sample_size = min(20, len(all_classes_names))\n","random_range = random.sample(all_classes_names, sample_size)\n","\n","for counter, selected_class_name in enumerate(random_range, 1):\n","    video_files_names_list = os.listdir(f'/content/drive/MyDrive/isl_data50/{selected_class_name}')\n","    selected_video_file_name = random.choice(video_files_names_list)\n","    video_reader = cv2.VideoCapture(f'/content/drive/MyDrive/isl_data50/{selected_class_name}/{selected_video_file_name}')\n","    _, bgr_frame = video_reader.read()\n","    video_reader.release()\n","    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n","    cv2.putText(rgb_frame, selected_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2)\n","    plt.subplot(5, 4, counter)\n","    plt.imshow(rgb_frame)\n","    plt.axis('off')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"08af84da","metadata":{"id":"08af84da"},"outputs":[],"source":["IMAGE_HEIGHT , IMAGE_WIDTH = 64,64\n","SEQUENCE_LENGTH = 50\n","DATASET_DIR = \"/content/drive/MyDrive/isl_data50\"\n","# CLASSES_LIST = [\"hot_Cropped\",\"lose_Cropped\",\"doctor_Cropped\", \"accident_Cropped\",\"help_Cropped\",\"call_Cropped\",\"thief_Cropped\",\"pain_Cropped\"]\n","CLASSES_LIST = []\n","folders = [f for f in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, f))]\n","for folder in folders:\n","    CLASSES_LIST.append(folder)"]},{"cell_type":"code","execution_count":null,"id":"772a88dc","metadata":{"id":"772a88dc"},"outputs":[],"source":["def frame_extraction(video_path):\n","    frame_list = []\n","    video_reader = cv2.VideoCapture(video_path)\n","    video_frame_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","    skip_frame_window = max(int(video_frame_count/SEQUENCE_LENGTH),1)\n","    for frame_counter in range(SEQUENCE_LENGTH):\n","        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter*skip_frame_window)\n","        success,frame = video_reader.read()\n","        if not success:\n","            break\n","        resized_frame = cv2.resize(frame,(IMAGE_HEIGHT,IMAGE_WIDTH))\n","        normalized_frame = resized_frame/255\n","        frame_list.append(normalized_frame)\n","    video_reader.release()\n","    return frame_list"]},{"cell_type":"code","execution_count":null,"id":"5e5c9cda","metadata":{"id":"5e5c9cda"},"outputs":[],"source":["def create_dataset():\n","    feature = []\n","    labels = []\n","    video_files_path = []\n","    for class_index, class_name in enumerate(CLASSES_LIST):\n","        print(f'Extracting Data of Class: {class_name}')\n","        files_list = os.listdir(os.path.join(DATASET_DIR,class_name))\n","        for file_name in files_list:\n","            video_file_path = os.path.join(DATASET_DIR,class_name,file_name)\n","            frame = frame_extraction(video_file_path)\n","            if(len(frame) == SEQUENCE_LENGTH):\n","                feature.append(frame)\n","                labels.append(class_index)\n","                video_files_path.append(video_file_path)\n","    feature = np.asarray(feature)\n","    labels = np.array(labels)\n","    return feature,labels,video_file_path\n"]},{"cell_type":"code","execution_count":null,"id":"7c0909a7","metadata":{"id":"7c0909a7","outputId":"9e3e2dd7-674c-4310-fa11-d0548d8a5353","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting Data of Class: White\n","Extracting Data of Class: Teacher\n","Extracting Data of Class: Summer\n","Extracting Data of Class: Window\n","Extracting Data of Class: you\n","Extracting Data of Class: Time\n","Extracting Data of Class: T-Shirt\n"]}],"source":["features,labels,video_file_paths = create_dataset()"]},{"cell_type":"code","execution_count":null,"id":"4cb0c727","metadata":{"id":"4cb0c727"},"outputs":[],"source":["one_hot_encoded_labels = to_categorical(labels)"]},{"cell_type":"code","execution_count":null,"id":"521d018e","metadata":{"id":"521d018e"},"outputs":[],"source":["features_train,features_test,labels_train,labels_test = train_test_split(features,one_hot_encoded_labels,test_size=0.25,shuffle=True,random_state=seed_constant)"]},{"cell_type":"code","execution_count":null,"id":"db501fe0","metadata":{"id":"db501fe0"},"outputs":[],"source":["from keras.layers import Conv2D, BatchNormalization, Bidirectional, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D,ConvLSTM2D,LSTM,GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D\n","from keras.layers import UpSampling2D, Input, Concatenate,TimeDistributed, Add, GlobalMaxPooling2D, Multiply, Permute, multiply,MaxPooling2D, MaxPooling3D, Dropout, Flatten, GlobalAveragePooling3D, GlobalMaxPooling3D\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau,EarlyStopping\n","from keras.metrics import Recall, Precision, Accuracy, MeanIoU\n","from keras import backend as K"]},{"cell_type":"code","execution_count":null,"id":"daff1046","metadata":{"id":"daff1046"},"outputs":[],"source":["def create_convlstm_model():\n","\n","    # We will use a Sequential model for model construction\n","    model = Sequential()\n","    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n","                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n","                                                                                      IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","\n","    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","    model.add(TimeDistributed(Dropout(0.2)))\n","\n","    model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n","                         recurrent_dropout=0.2, return_sequences=True))\n","\n","    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","    model.add(TimeDistributed(Dropout(0.2)))\n","\n","    model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n","                         recurrent_dropout=0.2, return_sequences=True))\n","\n","    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","    model.add(TimeDistributed(Dropout(0.2)))\n","\n","    model.add(ConvLSTM2D(filters = 128, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n","                         recurrent_dropout=0.2, return_sequences=True))\n","\n","    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","\n","    model.add(Flatten())\n","    model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n","    model.summary()\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"db3629b6","metadata":{"id":"db3629b6"},"outputs":[],"source":["# without attention\n","\n","convlstm_model = create_convlstm_model()\n","print(\"Model Created Successfully\")"]},{"cell_type":"code","execution_count":null,"id":"26fe85a2","metadata":{"id":"26fe85a2"},"outputs":[],"source":["# without attention\n","plot_model(convlstm_model, to_file = r\"C:\\Users\\ASUS\\Downloads\\experiment\\Conv-lstm\\convlstm.png\",show_shapes= True,show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"id":"5f406efe","metadata":{"id":"5f406efe"},"outputs":[],"source":["# Create an Instance of Early Stopping Callback\n","# without attention\n","import keras\n","from keras import layers\n","early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n","\n","# Compile the model and specify loss function, optimizer and metrics values to the model\n","# opt = keras.optimizers.Adam(learning_rate=0.01)\n","opt = keras.optimizers.Nadam(\n","    learning_rate=0.001,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=1e-07,\n","    weight_decay=None,\n","    clipnorm=None,\n","    clipvalue=None,\n","    global_clipnorm=None,\n","    use_ema=False,\n","    ema_momentum=0.99,\n","    ema_overwrite_frequency=None,\n","    name=\"nadam\",\n","\n",")\n","convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = [\"accuracy\"])\n","\n","# Start training the model. --> vary bacth size and epochs\n","convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 500, batch_size = 8,\n","                                                     shuffle = True, validation_split = 0.2,\n","                                                     callbacks = [early_stopping_callback])"]},{"cell_type":"code","execution_count":null,"id":"30e372dd","metadata":{"id":"30e372dd"},"outputs":[],"source":["model_evaluation_history = convlstm_model.evaluate(features_test,labels_test)"]},{"cell_type":"code","execution_count":null,"id":"959c02cc","metadata":{"id":"959c02cc"},"outputs":[],"source":["model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n","\n","date_time_format = '%Y_%m_%d__%H_%M_%S'\n","current_date_time_dt = dt.datetime.now()\n","current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n","\n","model_file_name = fr'C:\\Users\\ASUS\\Downloads\\experiment\\Conv-lstm\\convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n","\n","# Save your Model.\n","convlstm_model.save(model_file_name)"]},{"cell_type":"code","execution_count":null,"id":"1f353a05","metadata":{"id":"1f353a05"},"outputs":[],"source":["def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name, to_file = None):\n","\n","    # Get metric values using metric names as identifiers.\n","    metric_value_1 = model_training_history.history[metric_name_1]\n","    metric_value_2 = model_training_history.history[metric_name_2]\n","\n","    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n","    epochs = range(len(metric_value_1))\n","\n","    # Plot the Graph.\n","    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n","    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n","\n","    # Add title to the plot.\n","    plt.title(str(plot_name))\n","    if to_file:\n","        plt.savefig(to_file)\n","\n","    # Add legend to the plot.\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"id":"3542fbd6","metadata":{"id":"3542fbd6"},"outputs":[],"source":["# Visualize the training and validation loss metrices.\n","plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss', to_file = r\"C:\\Users\\ASUS\\Downloads\\experiment\\Conv-lstm\\loss.png\")"]},{"cell_type":"code","execution_count":null,"id":"5c1768e2","metadata":{"id":"5c1768e2"},"outputs":[],"source":["# Visualize the training and validation accuracy metrices.\n","plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy', to_file = r\"C:\\Users\\ASUS\\Downloads\\experiment\\Conv-lstm\\accuracy.png\")"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":5}